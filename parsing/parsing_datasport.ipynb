{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Data from [datasport.com](https://www.datasport.com/en/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use postman to understand the parameters used by the url request, asked for the exercise.\n",
    "\n",
    "(However, notice that there are equivalent tools for other browser - for instance, for firefox:\n",
    "http://stackoverflow.com/questions/28997326/postman-addons-like-in-firefox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important modules for this HW\n",
    "import bs4 # doc: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "import requests as rq \n",
    "import re\n",
    "\n",
    "# previous useful modules\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form_source = rq.get(\"https://www.datasport.com/en/\")\n",
    "form_soup = bs4.BeautifulSoup(form_source.text, \"html.parser\")\n",
    "# print(form_soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the `select` menus of the page, using the `find_all` method of *BeautifulSoup* which allows to search for all tags of a certain type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "selectors = form_soup.find_all('select')\n",
    "print(len(selectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most importantly, we can find out what each tag is about by printing the its `name` attribute :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select n°0 : etyp\n",
      "Select n°1 : eventmonth\n",
      "Select n°2 : eventyear\n",
      "Select n°3 : eventlocation\n"
     ]
    }
   ],
   "source": [
    "for num, s in enumerate(selectors):\n",
    "    print(\"Select n°{} : {}\".format(num, s.attrs['name'])) # wild french appears..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etyp:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- Cross-Country-Skiing [Cross-Country-Skiing]\n",
      "- Cycling [Cycling]\n",
      "- Cycling,MTB [Cycling,MTB]\n",
      "- Cycling,Others [Cycling,Others]\n",
      "- Duathlon [Duathlon]\n",
      "- Inline [Inline]\n",
      "- MTB [MTB]\n",
      "- MTB,Cycling [MTB,Cycling]\n",
      "- MTB,Cycling,Others [MTB,Cycling,Others]\n",
      "- MTB,Others [MTB,Others]\n",
      "- MTB,X-Hours [MTB,X-Hours]\n",
      "- Others [Others]\n",
      "- Others,Inline,Running,MTB [Others,Inline,Running,MTB]\n",
      "- Running [Running]\n",
      "- Running,Inline [Running,Inline]\n",
      "- Running,MTB [Running,MTB]\n",
      "- Running,MTB,Others [Running,MTB,Others]\n",
      "- Running,Skiing/Snowboard [Running,Skiing/Snowboard]\n",
      "- Running,Waffenlauf [Running,Waffenlauf]\n",
      "- Running,Walking [Running,Walking]\n",
      "- Running,Walking,MTB [Running,Walking,MTB]\n",
      "- Running,Walking,Others [Running,Walking,Others]\n",
      "- Running,X-Hours [Running,X-Hours]\n",
      "- Skiing/Snowboard [Skiing/Snowboard]\n",
      "- Triathlon [Triathlon]\n",
      "- Triathlon,Duathlon [Triathlon,Duathlon]\n",
      "- Triathlon,Others [Triathlon,Others]\n",
      "- Waffenlauf [Waffenlauf]\n",
      "- Walking [Walking]\n",
      "- X-Hours [X-Hours]\n",
      "- X-Hours,MTB [X-Hours,MTB]\n",
      "eventmonth:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- 01 [01]\n",
      "- 02 [02]\n",
      "- 03 [03]\n",
      "- 04 [04]\n",
      "- 05 [05]\n",
      "- 06 [06]\n",
      "- 07 [07]\n",
      "- 08 [08]\n",
      "- 09 [09]\n",
      "- 10 [10]\n",
      "- 11 [11]\n",
      "- 12 [12]\n",
      "eventyear:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- 2017 [2017]\n",
      "- 2016 [2016]\n",
      "- 2015 [2015]\n",
      "- 2014 [2014]\n",
      "- 2013 [2013]\n",
      "- 2012 [2012]\n",
      "- 2011 [2011]\n",
      "- 2010 [2010]\n",
      "- 2009 [2009]\n",
      "- 2008 [2008]\n",
      "- 2007 [2007]\n",
      "- 2006 [2006]\n",
      "- 2005 [2005]\n",
      "- 2004 [2004]\n",
      "- 2003 [2003]\n",
      "- 2002 [2002]\n",
      "- 2001 [2001]\n",
      "- 2000 [2000]\n",
      "- 1999 [1999]\n",
      "eventlocation:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- Aargau [RCH-AG]\n",
      "- Appenzell Innerhoden [RCH-AI]\n",
      "- Bern [RCH-BE]\n",
      "- Basel-Landschaft [RCH-BL]\n",
      "- Basel-Stadt [RCH-BS]\n",
      "- Fribourg [RCH-FR]\n",
      "- Geneva [RCH-GE]\n",
      "- Glarus [RCH-GL]\n",
      "- Graubünden [RCH-GR]\n",
      "- Lucerne [RCH-LU]\n",
      "- Neuchâtel [RCH-NE]\n",
      "- Nidwalden [RCH-NW]\n",
      "- Obwalden [RCH-OW]\n",
      "- St. Gallen [RCH-SG]\n",
      "- Schaffhausen [RCH-SH]\n",
      "- Solothurn [RCH-SO]\n",
      "- Schwyz [RCH-SZ]\n",
      "- Thurgau [RCH-TG]\n",
      "- Ticino [RCH-TI]\n",
      "- Uri [RCH-UR]\n",
      "- Vaud [RCH-VD]\n",
      "- Valais [RCH-VS]\n",
      "- Zug [RCH-ZG]\n",
      "- Zurich [RCH-ZH]\n",
      "- Vienna [RA-W]\n",
      "- Upper Austria [RA-O]\n",
      "- Salzburg [RA-SA]\n",
      "- Tyrol [RA-T]\n",
      "- Vorarlberg [RA-V]\n",
      "- Styria [RA-ST]\n",
      "- Carinthia [RA-K]\n",
      "- Baden-Württemberg [RD-BW]\n",
      "- Bavaria [RD-BY]\n",
      "- Berlin [RD-BE]\n",
      "- Hamburg [RD-HH]\n",
      "- Hesse [RD-HE]\n",
      "- Lower Saxony [RD-NI]\n",
      "- North Rhine-Westphalia [RD-NW]\n",
      "- Rhineland-Palatinate [RD-RP]\n",
      "- Saarland [RD-SL]\n",
      "- Saxony-Anhalt [RD-ST]\n",
      "- Schleswig-Holstein [RD-SH]\n",
      "- Franche-Comté [RF-I]\n",
      "- Languedoc-Roussillon [RF-K]\n",
      "- Nord - Pas-De-Calais [RF-O]\n",
      "- Poitou-Charentes [RF-T]\n",
      "- Rhône-Alpes [RF-V]\n",
      "- French Islands [RF-W]\n",
      "- Lombardy [RI-LOM]\n",
      "- Piedmont [RI-PMN]\n",
      "- Trentino South Tyrol [RI-TAA]\n",
      "- Veneto [RI-VEN]\n",
      "- Flevoland [RNL-FL]\n",
      "- Friesland [RNL-FR]\n",
      "- Gelderland [RNL-GE]\n",
      "- Groningen [RNL-GR]\n",
      "- Zuid Holland [RNL-ZH]\n",
      "- Blekinge län [RS-K]\n",
      "- Dalarnas län [RS-W]\n",
      "- Gotlands län [RS-I]\n",
      "- Örebro län [RS-T]\n",
      "- Västra Götalands län [RS-O]\n",
      "- ---- [all]\n",
      "- Austria [CA]\n",
      "- Belgium [CB]\n",
      "- Canada [CCAN]\n",
      "- France [CF]\n",
      "- Germany [CD]\n",
      "- Italy [CI]\n",
      "- Liechtenstein [CFL]\n",
      "- Norway [CN]\n",
      "- Switzerland [CCH]\n",
      "- United States [CUSA]\n"
     ]
    }
   ],
   "source": [
    "for s in selectors:\n",
    "    options = s.find_all('option')\n",
    "    options_desc_values = [(o.text, o.attrs['value']) for o in options]\n",
    "    print(s.attrs['name'] + ':')\n",
    "    for (d,v) in options_desc_values:\n",
    "        print(\"- {} [{}]\".format(d,v)) # more french"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get some data\n",
    "\n",
    "In order to get started, we can now start collecting the results from the Lausanne marathone, one of the main early event in Switzerland.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the html of the main page, and __extract the relevant parameters__ to query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the pages links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of categories in the main page: 86\n"
     ]
    }
   ],
   "source": [
    "laus_mar_url = 'https://services.datasport.com/2016/lauf/lamara/'\n",
    "fri_half_url = 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg/'\n",
    "german_mar_url='https://services.datasport.com/2014/lauf/grmarathon/'\n",
    "kapoag_url='https://services.datasport.com/2013/lauf/kapoag/'\n",
    "base_url=fri_half_url\n",
    "\n",
    "\n",
    "\n",
    "result_html = rq.get(base_url)\n",
    "\n",
    "# use BS to get the classes in which the data is devided:\n",
    "\n",
    "result_soup = bs4.BeautifulSoup(result_html.text, \"lxml\")\n",
    "result_font = result_soup.find_all('font')\n",
    "\n",
    "print('number of categories in the main page:', len(result_font))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAA.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAB.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAC.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAD.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAE.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAF.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAG.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAH.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAI.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAJ.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAK.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAL.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAM.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAN.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAO.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAP.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAR.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAS.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAT.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAU.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAV.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAW.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAY.HTM',\n",
       " 'https://services.datasport.com/2013/lauf/semi-marathon-fribourg//ALFAZ.HTM']"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we look for the ones containing \n",
    "# '*** Overall ***', as they are the most general categories \n",
    "\n",
    "# this is indeed probably a GENERAL KEYWORD, as it's indeed found also in\n",
    "# events in other laungauges, \n",
    "# like https://services.datasport.com/2016/lauf/ascona-locarno-marathon/\n",
    "\n",
    "base_url_lausanne = \"https://services.datasport.com/2016/lauf/lamara\"\n",
    "\n",
    "good_fonts_num = []\n",
    "\n",
    "links=[]\n",
    "for n_font, font in enumerate(result_font):\n",
    "#     print(font.findChild())\n",
    "    if font.get('size')=='3':\n",
    "        links_to_process=font.findAll('a')\n",
    "        for link in links_to_process:\n",
    "            link=str(link)\n",
    "            try:\n",
    "                link=link.split('\"')[1]\n",
    "                if link[:4]=='ALFA':\n",
    "                    links.append(base_url+'/'+link)\n",
    "            except:\n",
    "                pass\n",
    "        break\n",
    "links\n",
    "#     if 'Overall' in font.findChild().get_text():\n",
    "            \n",
    "#         good_fonts_num.append(n_font)\n",
    "#         print(font.findChild().get_text())\n",
    "        \n",
    "        \n",
    "# good_fonts_num = np.asarray(good_fonts_num)        \n",
    "        \n",
    "#  S***** -.- THERE IS A PROBLEM with the marathon hommes : \n",
    "# they are not in the same 'html shape' .. -.-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the datasport.com with the right parameters and finally get the __tables__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are more fields than that. These are the only the ones that matters\n",
    "# Important to automatically check if some tables are differently structured\n",
    "# Impossible to manually check all the tables for all the games.\n",
    "header_fields_french=[['catégorie'],['rang'],['nom'],['an'],['lieu','pays/lieu'],['équipe'],['pénalité'],['temps'],['retard']]\n",
    "optional_french=['pénalité']\n",
    "first_excluded_field_french='doss'\n",
    "header_fields_german=[['Kategorie'],['Rang'],['Name/Ort','Name'],['Jg'],['Team/Ortschaft','Land/Ort'],['Team'],['Zeit'],['Rückstand']]\n",
    "optional_german=['Team']\n",
    "first_excluded_field_german='Stnr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_time(time):\n",
    "    if time.count(',')==0:\n",
    "        raise()\n",
    "    time=re.split(\"[:.,]+\",time)\n",
    "    while len(time)<4:\n",
    "        time=[0]+time\n",
    "    hours,minutes,seconds,mseconds=[float(x) for x in time]\n",
    "    \n",
    "    return (hours,minutes,seconds,mseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_legend(legend):\n",
    "    penalty=True\n",
    "    \n",
    "    legend=str(legend).split('¦')[0]\n",
    "    legend=re.sub('<[^>]+>', ' ', legend)\n",
    "    legend=legend.lstrip()\n",
    "    \n",
    "    # check language\n",
    "    if legend.startswith(header_fields_french[0][0]):\n",
    "        language='French'\n",
    "        header_fields=header_fields_french\n",
    "        first_excluded=first_excluded_field_french\n",
    "        optional=optional_french\n",
    "    elif legend.startswith(header_fields_german[0][0]):\n",
    "        language='German'\n",
    "        header_fields=header_fields_german\n",
    "        first_excluded=first_excluded_field_german\n",
    "        optional=optional_german\n",
    "    else:\n",
    "        print(legend)\n",
    "        raise('Error, problems in language detection')\n",
    "        return '',False,True\n",
    "    \n",
    "    # Check if all words are present\n",
    "    for words in header_fields:\n",
    "        found=False\n",
    "        for word in words:\n",
    "            if legend.startswith(word):\n",
    "                legend=legend.split(word)[1]\n",
    "                legend=legend.lstrip()\n",
    "                found=True\n",
    "                break\n",
    "            \n",
    "        if found==False:\n",
    "            if words[0] in optional:\n",
    "                penalty=False\n",
    "            else:\n",
    "                print(words)\n",
    "                print(legend)\n",
    "                raise('Error, word not known')\n",
    "                return '',False,True\n",
    "    legend_first_excluded=legend.split(' ')[0]\n",
    "    if legend_first_excluded != first_excluded:\n",
    "        print(legend_first_excluded)\n",
    "        print(legend)\n",
    "        raise('First excluded element not good')\n",
    "    \n",
    "    \n",
    "    return language,False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT - TODO\n",
    "\n",
    "Remove walking data - the rang is not present in these dataset.\n",
    "It can cause problem for the splitting if nom is not a link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fields* - standard fields for each language:\n",
    "1. catégorie (0)\n",
    "2. rang (1) (CAN BE MERGED WITH NOM)\n",
    "3. nom (2) (CAN BE MERGED WITH RANG)\n",
    "4. an (3)\n",
    "5. lieu (3)\n",
    "6. équipe  (4) (MAYBE MISSING)\n",
    "7. pénalité (5) (NOT ALWAYS PRESENT)\n",
    "8. temps (6)\n",
    "9. retard (7)\n",
    "\n",
    "*Only* 1,2,3,4,8,9 are parsed!!\n",
    "After 4, it checks if the other fields are a time field. If they are not, they are not used.\n",
    "If more than 2 times are found an error is raised.\n",
    "If 1 time is found it is supposed that it is the final time, not the delay.\n",
    "If 0 times are found the player is not used and it is printed\n",
    "\n",
    "The presence of these fields is automatically checked. They have to be in this order.\n",
    "If they are not, an error is raised.\n",
    "Other possible problems:\n",
    "1. temps and retard should be formatted in a way parsable by parse_time()\n",
    "2. Also the other fields should be formatted in the same way as Lausanne Marathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_fields(runner_splitted):\n",
    "    fields_processed=[]\n",
    "    # The first 3 elements are the same\n",
    "    fields_processed.append(runner_splitted[0])\n",
    "    # Check if splitting second element\n",
    "    splitted=runner_splitted[1].split('.')\n",
    "    first_to_check=3\n",
    "    if len(splitted)!=1 and splitted[1]!='': #rang and nom are merged\n",
    "        splitted[1]=splitted[1].lstrip()\n",
    "        fields_processed+=splitted\n",
    "        first_to_check=2\n",
    "    else:\n",
    "        fields_processed.append(splitted[0])\n",
    "        fields_processed.append(runner_splitted[2])\n",
    "        \n",
    "    # Split the an-lieu element\n",
    "    fields_processed+=runner_splitted[first_to_check].split(' ',1)\n",
    "    first_to_check+=1\n",
    "    \n",
    "    # Take only the first element (the year). The second is kept only if it is a time (not encountered yet)\n",
    "    try:\n",
    "        parse_time(fields_processed[-1])\n",
    "    except:\n",
    "        del fields_processed[-1]\n",
    "    \n",
    "    # Insert all times found after the year (if they are not 2 raise an error)\n",
    "    added_fields=0\n",
    "    for i in range(first_to_check,len(runner_splitted)):\n",
    "        try:\n",
    "            parse_time(runner_splitted[i])\n",
    "            fields_processed.append(runner_splitted[i])\n",
    "            added_fields+=1\n",
    "        except:\n",
    "            pass\n",
    "    if added_fields==0:\n",
    "        return []\n",
    "    if added_fields==1:\n",
    "        fields_processed.append('----')\n",
    "        added_fields=2\n",
    "    if added_fields!=2:\n",
    "        print(added_fields)\n",
    "        print(runner_splitted)\n",
    "        raise('Added fields not equal to 2')\n",
    "    \n",
    "    \n",
    "#     team_field_present=True\n",
    "#     field_to_check=4+penalty\n",
    "#     try:\n",
    "#         parse_time(runner_splitted[field_to_check]) # It should raise error if field not missing\n",
    "#         fields_processed.append('')\n",
    "#         team_field_present=False\n",
    "#     except:\n",
    "#         pass\n",
    "   \n",
    "#     fields_processed+=runner_splitted[4:6+penalty+team_field_present]\n",
    "    \n",
    "    \n",
    "    return fields_processed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n",
      "French False\n"
     ]
    }
   ],
   "source": [
    "final_list=[]\n",
    "for link in links:\n",
    "    # Get raw HTML response\n",
    "    result_html = rq.get(link)#, params=rang_to_query[0])\n",
    "\n",
    "    # Use BeautifulSoup and extract the first (and only) HTML table\n",
    "    result_soup = bs4.BeautifulSoup(result_html.text, \"lxml\")\n",
    "\n",
    "    results=result_soup.findAll('font')  # Search for all fonts\n",
    "    language,errors=process_legend(results[0])\n",
    "    print(language,errors)\n",
    "    del results[0]    # This is the legend\n",
    "    for table in results:\n",
    "        if table.get('size')=='2': # If size is 1 it stores the split times, not interesting\n",
    "            \n",
    "            # NOT TRUE IN GENERAL !!!!!!!!!!!!!!!!!!!!\n",
    "            runner_list=str(table).split('\\n')         # Each line is delimited by ¦\n",
    "            for k,runner in enumerate(runner_list):\n",
    "                start_runner=runner[:]\n",
    "                runner=re.sub('<[^>]+>', ' ', runner) # Remove all text between <>\n",
    "                runner=re.sub('  +','#@$&',runner)       # Replace all the double or more spaces with &\n",
    "                \n",
    "                runner=runner.replace('\\n','')        # Remove the \\n at the beginning of the line\n",
    "                \n",
    "\n",
    "                runner=runner.replace(' \\r','')       # Remove the \\r at the beginning of the line\n",
    "                runner=runner.replace('\\r','')       # Remove the \\r at the beginning of the line\n",
    "                runner=runner.lstrip()                 # The first athlete starts with a space\n",
    "#                 print(repr(runner))\n",
    "#                 print()\n",
    "                # The team can be empty, check:\n",
    "                counter=runner.count('#@$&')\n",
    "                start=runner[:3]\n",
    "                if start=='10-' or start=='21-' or start=='42-':\n",
    "                    runner2=runner.split('#@$&')          # Split the fields\n",
    "                    \n",
    "                    # It works ONLY if the number of fields are the same for different languages\n",
    "                    runner=process_fields(runner2) \n",
    "                    if len(runner)!=0:\n",
    "                        final_list.append(runner)         # Append to the final list  \n",
    "                    else:\n",
    "                        print(start_runner)\n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1555, 6)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(final_list)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-F20</td>\n",
       "      <td>83</td>\n",
       "      <td>Achermann Nathalie</td>\n",
       "      <td>1974</td>\n",
       "      <td>1:03.37,0</td>\n",
       "      <td>26.23,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21-F20</td>\n",
       "      <td>46</td>\n",
       "      <td>Aebi Christina</td>\n",
       "      <td>1979</td>\n",
       "      <td>1:51.42,5</td>\n",
       "      <td>32.37,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>102</td>\n",
       "      <td>Aebi Mikael</td>\n",
       "      <td>1982</td>\n",
       "      <td>1:38.29,8</td>\n",
       "      <td>31.40,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-F20</td>\n",
       "      <td>41</td>\n",
       "      <td>Aebi Patrizia</td>\n",
       "      <td>1974</td>\n",
       "      <td>53.56,8</td>\n",
       "      <td>16.42,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-F20</td>\n",
       "      <td>25</td>\n",
       "      <td>Aebischer Elizabeth</td>\n",
       "      <td>1974</td>\n",
       "      <td>49.48,0</td>\n",
       "      <td>12.34,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10-F20</td>\n",
       "      <td>43</td>\n",
       "      <td>Aebischer Marie-Christine</td>\n",
       "      <td>1976</td>\n",
       "      <td>54.13,8</td>\n",
       "      <td>16.59,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21-F40</td>\n",
       "      <td>91</td>\n",
       "      <td>Aebischer Murielle</td>\n",
       "      <td>1972</td>\n",
       "      <td>2:02.46,0</td>\n",
       "      <td>37.46,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21-M40</td>\n",
       "      <td>241</td>\n",
       "      <td>Aebischer Pascal</td>\n",
       "      <td>1971</td>\n",
       "      <td>2:02.46,1</td>\n",
       "      <td>45.38,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>62</td>\n",
       "      <td>Aebischer Patrick</td>\n",
       "      <td>1984</td>\n",
       "      <td>1:33.29,2</td>\n",
       "      <td>26.39,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>159</td>\n",
       "      <td>Aebischer Sascha</td>\n",
       "      <td>1975</td>\n",
       "      <td>1:44.48,1</td>\n",
       "      <td>37.58,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>236</td>\n",
       "      <td>Aeby Bastien</td>\n",
       "      <td>1981</td>\n",
       "      <td>1:59.48,0</td>\n",
       "      <td>52.58,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21-M40</td>\n",
       "      <td>55</td>\n",
       "      <td>Aeby Patrik</td>\n",
       "      <td>1972</td>\n",
       "      <td>1:34.23,8</td>\n",
       "      <td>17.15,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10-M20</td>\n",
       "      <td>27</td>\n",
       "      <td>Aeby Vincent</td>\n",
       "      <td>1985</td>\n",
       "      <td>43.10,6</td>\n",
       "      <td>10.58,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10-Walk</td>\n",
       "      <td>---</td>\n",
       "      <td>Aegerter Gerda</td>\n",
       "      <td>1962</td>\n",
       "      <td>1:30.33,9</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21-F60</td>\n",
       "      <td>2</td>\n",
       "      <td>Aerni Erika</td>\n",
       "      <td>1950</td>\n",
       "      <td>2:00.20,7</td>\n",
       "      <td>2.19,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21-M50</td>\n",
       "      <td>76</td>\n",
       "      <td>Aeschlimann Urs</td>\n",
       "      <td>1963</td>\n",
       "      <td>1:47.14,7</td>\n",
       "      <td>31.20,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21-M50</td>\n",
       "      <td>31</td>\n",
       "      <td>Albrecht Urs</td>\n",
       "      <td>1962</td>\n",
       "      <td>1:39.00,1</td>\n",
       "      <td>23.05,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21-MU20</td>\n",
       "      <td>2</td>\n",
       "      <td>Alexander Raphaël</td>\n",
       "      <td>1994</td>\n",
       "      <td>1:51.05,0</td>\n",
       "      <td>16.13,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>65</td>\n",
       "      <td>Allahabadi Sachin</td>\n",
       "      <td>1991</td>\n",
       "      <td>1:33.54,1</td>\n",
       "      <td>27.04,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>91</td>\n",
       "      <td>Almeida Nuno</td>\n",
       "      <td>1980</td>\n",
       "      <td>1:36.43,2</td>\n",
       "      <td>29.53,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10-F20</td>\n",
       "      <td>45</td>\n",
       "      <td>Amiguet Mélanie</td>\n",
       "      <td>1983</td>\n",
       "      <td>54.28,3</td>\n",
       "      <td>17.14,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10-M40</td>\n",
       "      <td>4</td>\n",
       "      <td>Amoos Patrick</td>\n",
       "      <td>1971</td>\n",
       "      <td>36.01,8</td>\n",
       "      <td>3.44,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21-M40</td>\n",
       "      <td>154</td>\n",
       "      <td>Amore Marcel</td>\n",
       "      <td>1972</td>\n",
       "      <td>1:48.12,2</td>\n",
       "      <td>31.04,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>101</td>\n",
       "      <td>Amraoui Abdelaziz</td>\n",
       "      <td>1978</td>\n",
       "      <td>1:38.29,3</td>\n",
       "      <td>31.39,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21-M50</td>\n",
       "      <td>138</td>\n",
       "      <td>Amrein Alfred</td>\n",
       "      <td>1959</td>\n",
       "      <td>2:12.56,7</td>\n",
       "      <td>57.02,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21-F40</td>\n",
       "      <td>78</td>\n",
       "      <td>Amrein-Sauter Béatrice</td>\n",
       "      <td>1971</td>\n",
       "      <td>1:59.48,8</td>\n",
       "      <td>34.49,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21-F20</td>\n",
       "      <td>11</td>\n",
       "      <td>Amsler Daniela</td>\n",
       "      <td>1979</td>\n",
       "      <td>1:41.06,2</td>\n",
       "      <td>22.01,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21-F50</td>\n",
       "      <td>5</td>\n",
       "      <td>Andrey Angèle</td>\n",
       "      <td>1959</td>\n",
       "      <td>1:43.20,2</td>\n",
       "      <td>3.49,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10-Walk</td>\n",
       "      <td>---</td>\n",
       "      <td>Andrey Béatrice</td>\n",
       "      <td>1956</td>\n",
       "      <td>1:21.41,2</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10-M20</td>\n",
       "      <td>16</td>\n",
       "      <td>Andrey Maurice</td>\n",
       "      <td>1991</td>\n",
       "      <td>39.26,5</td>\n",
       "      <td>7.14,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>254</td>\n",
       "      <td>Zbären Sébastien</td>\n",
       "      <td>1979</td>\n",
       "      <td>2:06.16,6</td>\n",
       "      <td>59.27,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>21-M60</td>\n",
       "      <td>1</td>\n",
       "      <td>Zbinden Josef</td>\n",
       "      <td>1948</td>\n",
       "      <td>1:33.49,6</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>10-F20</td>\n",
       "      <td>10</td>\n",
       "      <td>Zbinden Laurie</td>\n",
       "      <td>1989</td>\n",
       "      <td>45.55,8</td>\n",
       "      <td>8.41,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>21-M60</td>\n",
       "      <td>7</td>\n",
       "      <td>Zbinden Marius</td>\n",
       "      <td>1950</td>\n",
       "      <td>1:41.03,8</td>\n",
       "      <td>7.14,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>21-M40</td>\n",
       "      <td>141</td>\n",
       "      <td>Zbinden Roland</td>\n",
       "      <td>1973</td>\n",
       "      <td>1:46.16,7</td>\n",
       "      <td>29.08,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>10-M50</td>\n",
       "      <td>21</td>\n",
       "      <td>Zbinden Willy</td>\n",
       "      <td>1958</td>\n",
       "      <td>52.01,4</td>\n",
       "      <td>18.16,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>168</td>\n",
       "      <td>Ze Jacques</td>\n",
       "      <td>1980</td>\n",
       "      <td>1:46.29,0</td>\n",
       "      <td>39.39,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>239</td>\n",
       "      <td>Zecchin Aurélien</td>\n",
       "      <td>1986</td>\n",
       "      <td>2:00.17,4</td>\n",
       "      <td>53.27,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>40</td>\n",
       "      <td>Zechner Johannes</td>\n",
       "      <td>1983</td>\n",
       "      <td>1:29.31,8</td>\n",
       "      <td>22.42,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>21-Walk</td>\n",
       "      <td>---</td>\n",
       "      <td>Zehnder Anita</td>\n",
       "      <td>1985</td>\n",
       "      <td>3:00.30,2</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>21-M40</td>\n",
       "      <td>135</td>\n",
       "      <td>Zermatten Stéphane</td>\n",
       "      <td>1971</td>\n",
       "      <td>1:45.28,8</td>\n",
       "      <td>28.20,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>10-M50</td>\n",
       "      <td>28</td>\n",
       "      <td>Ziazi Najib</td>\n",
       "      <td>1963</td>\n",
       "      <td>1:15.47,6</td>\n",
       "      <td>42.02,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>21-F20</td>\n",
       "      <td>39</td>\n",
       "      <td>Zimmerli Anita</td>\n",
       "      <td>1986</td>\n",
       "      <td>1:50.27,6</td>\n",
       "      <td>31.22,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>21-M60</td>\n",
       "      <td>6</td>\n",
       "      <td>Zimmermann Leo</td>\n",
       "      <td>1952</td>\n",
       "      <td>1:40.31,0</td>\n",
       "      <td>6.41,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>21-M50</td>\n",
       "      <td>56</td>\n",
       "      <td>Zimmermann René</td>\n",
       "      <td>1961</td>\n",
       "      <td>1:43.35,5</td>\n",
       "      <td>27.41,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>21-Walk</td>\n",
       "      <td>---</td>\n",
       "      <td>Zinguinian Hratch</td>\n",
       "      <td>1946</td>\n",
       "      <td>3:15.50,4</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>21-Walk</td>\n",
       "      <td>---</td>\n",
       "      <td>Zinguinian Méliné</td>\n",
       "      <td>1980</td>\n",
       "      <td>2:55.49,2</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>21-F40</td>\n",
       "      <td>8</td>\n",
       "      <td>Zisch Corinne</td>\n",
       "      <td>1964</td>\n",
       "      <td>1:32.54,9</td>\n",
       "      <td>7.55,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>21-F40</td>\n",
       "      <td>113</td>\n",
       "      <td>Zizza Laurence</td>\n",
       "      <td>1970</td>\n",
       "      <td>2:10.04,7</td>\n",
       "      <td>45.05,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>21-M40</td>\n",
       "      <td>71</td>\n",
       "      <td>Zobrist Christoph</td>\n",
       "      <td>1969</td>\n",
       "      <td>1:37.39,0</td>\n",
       "      <td>20.31,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>10-F20</td>\n",
       "      <td>27</td>\n",
       "      <td>Zollinger Marie</td>\n",
       "      <td>1988</td>\n",
       "      <td>50.47,8</td>\n",
       "      <td>13.33,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>10-M50</td>\n",
       "      <td>18</td>\n",
       "      <td>Zollinger Michel</td>\n",
       "      <td>1960</td>\n",
       "      <td>50.47,6</td>\n",
       "      <td>17.02,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>21-M50</td>\n",
       "      <td>78</td>\n",
       "      <td>Zosso Jean-Marie</td>\n",
       "      <td>1954</td>\n",
       "      <td>1:48.12,2</td>\n",
       "      <td>32.17,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>21-F20</td>\n",
       "      <td>5</td>\n",
       "      <td>Zosso Melanie</td>\n",
       "      <td>1987</td>\n",
       "      <td>1:33.30,7</td>\n",
       "      <td>14.25,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>21-F20</td>\n",
       "      <td>103</td>\n",
       "      <td>Zuchuat Kristel</td>\n",
       "      <td>1985</td>\n",
       "      <td>2:04.21,6</td>\n",
       "      <td>45.16,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>21-F20</td>\n",
       "      <td>9</td>\n",
       "      <td>Zülli Aline</td>\n",
       "      <td>1989</td>\n",
       "      <td>1:40.28,3</td>\n",
       "      <td>21.23,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>10-Walk</td>\n",
       "      <td>---</td>\n",
       "      <td>Züllig Martina</td>\n",
       "      <td>1978</td>\n",
       "      <td>1:40.21,0</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>10-F40</td>\n",
       "      <td>38</td>\n",
       "      <td>Zumbrunnen Véronique</td>\n",
       "      <td>1966</td>\n",
       "      <td>58.23,2</td>\n",
       "      <td>22.08,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>21-M20</td>\n",
       "      <td>134</td>\n",
       "      <td>Zwahlen Keshab</td>\n",
       "      <td>1975</td>\n",
       "      <td>1:41.46,3</td>\n",
       "      <td>34.56,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>21-Walk</td>\n",
       "      <td>---</td>\n",
       "      <td>Zwahlen Renate</td>\n",
       "      <td>1979</td>\n",
       "      <td>3:10.59,3</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1555 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1                          2     3          4        5\n",
       "0      10-F20   83         Achermann Nathalie  1974  1:03.37,0  26.23,1\n",
       "1      21-F20   46             Aebi Christina  1979  1:51.42,5  32.37,7\n",
       "2      21-M20  102                Aebi Mikael  1982  1:38.29,8  31.40,3\n",
       "3      10-F20   41              Aebi Patrizia  1974    53.56,8  16.42,9\n",
       "4      10-F20   25        Aebischer Elizabeth  1974    49.48,0  12.34,1\n",
       "5      10-F20   43  Aebischer Marie-Christine  1976    54.13,8  16.59,9\n",
       "6      21-F40   91         Aebischer Murielle  1972  2:02.46,0  37.46,7\n",
       "7      21-M40  241           Aebischer Pascal  1971  2:02.46,1  45.38,1\n",
       "8      21-M20   62          Aebischer Patrick  1984  1:33.29,2  26.39,7\n",
       "9      21-M20  159           Aebischer Sascha  1975  1:44.48,1  37.58,6\n",
       "10     21-M20  236               Aeby Bastien  1981  1:59.48,0  52.58,5\n",
       "11     21-M40   55                Aeby Patrik  1972  1:34.23,8  17.15,8\n",
       "12     10-M20   27               Aeby Vincent  1985    43.10,6  10.58,5\n",
       "13    10-Walk  ---             Aegerter Gerda  1962  1:30.33,9     ----\n",
       "14     21-F60    2                Aerni Erika  1950  2:00.20,7   2.19,6\n",
       "15     21-M50   76            Aeschlimann Urs  1963  1:47.14,7  31.20,4\n",
       "16     21-M50   31               Albrecht Urs  1962  1:39.00,1  23.05,8\n",
       "17    21-MU20    2          Alexander Raphaël  1994  1:51.05,0  16.13,4\n",
       "18     21-M20   65          Allahabadi Sachin  1991  1:33.54,1  27.04,6\n",
       "19     21-M20   91               Almeida Nuno  1980  1:36.43,2  29.53,7\n",
       "20     10-F20   45            Amiguet Mélanie  1983    54.28,3  17.14,4\n",
       "21     10-M40    4              Amoos Patrick  1971    36.01,8   3.44,4\n",
       "22     21-M40  154               Amore Marcel  1972  1:48.12,2  31.04,2\n",
       "23     21-M20  101          Amraoui Abdelaziz  1978  1:38.29,3  31.39,8\n",
       "24     21-M50  138              Amrein Alfred  1959  2:12.56,7  57.02,4\n",
       "25     21-F40   78     Amrein-Sauter Béatrice  1971  1:59.48,8  34.49,5\n",
       "26     21-F20   11             Amsler Daniela  1979  1:41.06,2  22.01,4\n",
       "27     21-F50    5              Andrey Angèle  1959  1:43.20,2   3.49,0\n",
       "28    10-Walk  ---            Andrey Béatrice  1956  1:21.41,2     ----\n",
       "29     10-M20   16             Andrey Maurice  1991    39.26,5   7.14,4\n",
       "...       ...  ...                        ...   ...        ...      ...\n",
       "1525   21-M20  254           Zbären Sébastien  1979  2:06.16,6  59.27,1\n",
       "1526   21-M60    1              Zbinden Josef  1948  1:33.49,6     ----\n",
       "1527   10-F20   10             Zbinden Laurie  1989    45.55,8   8.41,9\n",
       "1528   21-M60    7             Zbinden Marius  1950  1:41.03,8   7.14,2\n",
       "1529   21-M40  141             Zbinden Roland  1973  1:46.16,7  29.08,7\n",
       "1530   10-M50   21              Zbinden Willy  1958    52.01,4  18.16,1\n",
       "1531   21-M20  168                 Ze Jacques  1980  1:46.29,0  39.39,5\n",
       "1532   21-M20  239           Zecchin Aurélien  1986  2:00.17,4  53.27,9\n",
       "1533   21-M20   40           Zechner Johannes  1983  1:29.31,8  22.42,3\n",
       "1534  21-Walk  ---              Zehnder Anita  1985  3:00.30,2     ----\n",
       "1535   21-M40  135         Zermatten Stéphane  1971  1:45.28,8  28.20,8\n",
       "1536   10-M50   28                Ziazi Najib  1963  1:15.47,6  42.02,3\n",
       "1537   21-F20   39             Zimmerli Anita  1986  1:50.27,6  31.22,8\n",
       "1538   21-M60    6             Zimmermann Leo  1952  1:40.31,0   6.41,4\n",
       "1539   21-M50   56            Zimmermann René  1961  1:43.35,5  27.41,2\n",
       "1540  21-Walk  ---          Zinguinian Hratch  1946  3:15.50,4     ----\n",
       "1541  21-Walk  ---          Zinguinian Méliné  1980  2:55.49,2     ----\n",
       "1542   21-F40    8              Zisch Corinne  1964  1:32.54,9   7.55,6\n",
       "1543   21-F40  113             Zizza Laurence  1970  2:10.04,7  45.05,4\n",
       "1544   21-M40   71          Zobrist Christoph  1969  1:37.39,0  20.31,0\n",
       "1545   10-F20   27            Zollinger Marie  1988    50.47,8  13.33,9\n",
       "1546   10-M50   18           Zollinger Michel  1960    50.47,6  17.02,3\n",
       "1547   21-M50   78           Zosso Jean-Marie  1954  1:48.12,2  32.17,9\n",
       "1548   21-F20    5              Zosso Melanie  1987  1:33.30,7  14.25,9\n",
       "1549   21-F20  103            Zuchuat Kristel  1985  2:04.21,6  45.16,8\n",
       "1550   21-F20    9                Zülli Aline  1989  1:40.28,3  21.23,5\n",
       "1551  10-Walk  ---             Züllig Martina  1978  1:40.21,0     ----\n",
       "1552   10-F40   38       Zumbrunnen Véronique  1966    58.23,2  22.08,6\n",
       "1553   21-M20  134             Zwahlen Keshab  1975  1:41.46,3  34.56,8\n",
       "1554  21-Walk  ---             Zwahlen Renate  1979  3:10.59,3     ----\n",
       "\n",
       "[1555 rows x 6 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ******* ******* ******* ******* *******  \n",
    "# OLD CODE \n",
    "# ******* ******* ******* ******* ******* ******* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_html(result_table.decode())[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = df.loc[1]                # use row 2 as column names\n",
    "df = df.drop([0, 1])                  # drop useless first rows\n",
    "df = df.drop([np.nan], axis=1)        # drop useless nan column\n",
    "df.index = df['No Sciper']            # use sciper column as index\n",
    "\n",
    "# Drop some columns\n",
    "df = df.drop(['Orientation Bachelor', 'Orientation Master', 'Filière opt.', 'Type Echange', 'Ecole Echange'], axis=1)\n",
    "\n",
    "# Do some renaming\n",
    "df.index.name = 'sciper'\n",
    "df.columns = ['gender', 'full_name', 'specialization', 'minor', 'status', 'sciper']\n",
    "\n",
    "# Map gender to more standard names\n",
    "dict_gender = {'Monsieur': 'male','Madame': 'female'}\n",
    "df.gender.replace(dict_gender, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tools\n",
    "\n",
    "We can define a helper function which, given a base URL and a dictionary of parameters, will fetch the data and fill a DataFrame with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(base_url, params_dict):\n",
    "    \"\"\"Get data from IS-Academia in a pandas DataFrame\"\"\"\n",
    "    \n",
    "    # Same sequence of operations of above, with a check if the result_table is empty\n",
    "    \n",
    "    result_html = rq.get(base_url,params=params_dict)\n",
    "    result_soup = bs4.BeautifulSoup(result_html.text, \"lxml\")\n",
    "    result_table = result_soup.find_all('table')[0]\n",
    "    \n",
    "    if (result_table.text == ''):\n",
    "        # Return empty dataframe\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        # Build a DataFrame containing the data, with SCIPER as index\n",
    "        df = pd.read_html(result_table.decode())[0]\n",
    "        try:\n",
    "            df.columns = df.loc[1]                # use 2nd row as column names\n",
    "            df = df.drop([0, 1])                  # drop useless first rows\n",
    "            df = df.drop([np.nan], axis=1)        # drop useless nan column\n",
    "            df.index = df['No Sciper']            # use sciper column as index\n",
    "        \n",
    "            # Drop some columns\n",
    "            df = df.drop(['Orientation Bachelor', 'Orientation Master', 'Filière opt.', 'Type Echange', 'Ecole Echange'], axis=1)\n",
    "            # Do some renaming\n",
    "            df.index.name = 'sciper'\n",
    "            df.columns = ['gender', 'full_name', 'specialization', 'minor', 'status', 'sciper']\n",
    "            # Map gender to more standard names\n",
    "            dict_gender = {'Monsieur': 'male','Madame': 'female'}\n",
    "            df.gender.replace(dict_gender, inplace=True)\n",
    "        except:\n",
    "            df = pd.DataFrame()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines test this function with hardcoded values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_url = \"http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.html?\"\n",
    "params_dict = {\n",
    "    'ww_x_GPS': 2021043255,\n",
    "    'ww_i_reportModel': 133685247,\n",
    "    'ww_i_reportModelXsl': 133685270,\n",
    "    'ww_x_UNITE_ACAD': 249847,\n",
    "    'ww_x_PERIODE_ACAD': 355925344,\n",
    "    'ww_x_PERIODE_PEDAGO': 249108,\n",
    "    'ww_x_HIVERETE':2936286\n",
    "}\n",
    "\n",
    "get_data(base_url, params_dict).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's get all the possible values in a cleaner way and keep them in variables that we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acad_period = {}\n",
    "level = {}\n",
    "semester = {}\n",
    "acad_unit = {}\n",
    "\n",
    "for s in selectors:\n",
    "    options = s.find_all('option')\n",
    "    options_desc_values = [(o.text, o.attrs['value']) for o in options]\n",
    "    s_name = s.attrs['name']\n",
    "    choices = {d: int(v) for (d,v) in options_desc_values if d!=''}\n",
    "    \n",
    "    if s_name == 'ww_x_PERIODE_ACAD':\n",
    "        acad_period = choices\n",
    "    elif s_name == 'ww_x_PERIODE_PEDAGO':\n",
    "        level = choices\n",
    "    elif s_name == 'ww_x_HIVERETE':\n",
    "        for (d,v) in options_desc_values:\n",
    "            if 'automne' in d:\n",
    "                semester['automne'] = int(v)\n",
    "            elif 'printemps' in d:\n",
    "                semester['printemps'] =int(v)\n",
    "    elif s_name == 'ww_x_UNITE_ACAD':\n",
    "        acad_unit = choices\n",
    "\n",
    "# Example of result\n",
    "acad_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get bachelor data for every year and store it if it's not empty\n",
    "import os\n",
    "local_dir = '.local-data'\n",
    "try:\n",
    "    os.mkdir(local_dir)\n",
    "except FileExistsError:\n",
    "    # directory exists\n",
    "    print(\"Using existing '\" + local_dir + \"' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fixed values\n",
    "params_dict = {\n",
    "    'ww_x_GPS': -1,\n",
    "    'ww_i_reportModel': 133685247,\n",
    "    'ww_i_reportModelXsl': 133685270,\n",
    "    'ww_x_UNITE_ACAD': acad_unit['Informatique']\n",
    "}\n",
    "\n",
    "# Iterate over all the varying params and keep only data for bachelors\n",
    "for year_key, year_value in acad_period.items():\n",
    "    for level_key, level_value in level.items():\n",
    "        for semester_key, semester_value in semester.items():\n",
    "            if 'bachelor' in level_key.lower():\n",
    "                params_dict['ww_x_PERIODE_ACAD'] = year_value\n",
    "                params_dict['ww_x_PERIODE_PEDAGO'] = level_value\n",
    "                params_dict['ww_x_HIVERETE'] = semester_value\n",
    "                \n",
    "                df = get_data(base_url, params_dict)\n",
    "                if not df.empty:\n",
    "                    # Persist dataframe locally with pickle\n",
    "                    filename = year_key + '-' + level_key.replace(' ', '-').lower() + '-' + semester_key\n",
    "                    df.to_pickle(local_dir + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the previous cell should download 60 files!, as you can check with this command:\n",
    "print(len([name for name in os.listdir(local_dir)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hereby show an example of dataframe laoded from the files previously download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_example = pd.read_pickle(local_dir + '/2007-2008-bachelor-semestre-6-printemps')\n",
    "df_example.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
