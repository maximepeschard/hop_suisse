{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Data from [datasport.com](https://www.datasport.com/en/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use postman to understand the parameters used by the url request, asked for the exercise.\n",
    "\n",
    "(However, notice that there are equivalent tools for other browser - for instance, for firefox:\n",
    "http://stackoverflow.com/questions/28997326/postman-addons-like-in-firefox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important modules for this HW\n",
    "import bs4 # doc: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "import requests as rq \n",
    "import re\n",
    "\n",
    "# previous useful modules\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form_source = rq.get(\"https://www.datasport.com/en/\")\n",
    "form_soup = bs4.BeautifulSoup(form_source.text, \"html.parser\")\n",
    "# print(form_soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the `select` menus of the page, using the `find_all` method of *BeautifulSoup* which allows to search for all tags of a certain type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "selectors = form_soup.find_all('select')\n",
    "print(len(selectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most importantly, we can find out what each tag is about by printing the its `name` attribute :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select n°0 : etyp\n",
      "Select n°1 : eventmonth\n",
      "Select n°2 : eventyear\n",
      "Select n°3 : eventlocation\n"
     ]
    }
   ],
   "source": [
    "for num, s in enumerate(selectors):\n",
    "    print(\"Select n°{} : {}\".format(num, s.attrs['name'])) # wild french appears..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etyp:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- Cross-Country-Skiing [Cross-Country-Skiing]\n",
      "- Cycling [Cycling]\n",
      "- Cycling,MTB [Cycling,MTB]\n",
      "- Cycling,Others [Cycling,Others]\n",
      "- Duathlon [Duathlon]\n",
      "- Inline [Inline]\n",
      "- MTB [MTB]\n",
      "- MTB,Cycling [MTB,Cycling]\n",
      "- MTB,Cycling,Others [MTB,Cycling,Others]\n",
      "- MTB,Others [MTB,Others]\n",
      "- MTB,X-Hours [MTB,X-Hours]\n",
      "- Others [Others]\n",
      "- Others,Inline,Running,MTB [Others,Inline,Running,MTB]\n",
      "- Running [Running]\n",
      "- Running,Inline [Running,Inline]\n",
      "- Running,MTB [Running,MTB]\n",
      "- Running,MTB,Others [Running,MTB,Others]\n",
      "- Running,Skiing/Snowboard [Running,Skiing/Snowboard]\n",
      "- Running,Waffenlauf [Running,Waffenlauf]\n",
      "- Running,Walking [Running,Walking]\n",
      "- Running,Walking,MTB [Running,Walking,MTB]\n",
      "- Running,Walking,Others [Running,Walking,Others]\n",
      "- Running,X-Hours [Running,X-Hours]\n",
      "- Skiing/Snowboard [Skiing/Snowboard]\n",
      "- Triathlon [Triathlon]\n",
      "- Triathlon,Duathlon [Triathlon,Duathlon]\n",
      "- Triathlon,Others [Triathlon,Others]\n",
      "- Waffenlauf [Waffenlauf]\n",
      "- Walking [Walking]\n",
      "- X-Hours [X-Hours]\n",
      "- X-Hours,MTB [X-Hours,MTB]\n",
      "eventmonth:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- 01 [01]\n",
      "- 02 [02]\n",
      "- 03 [03]\n",
      "- 04 [04]\n",
      "- 05 [05]\n",
      "- 06 [06]\n",
      "- 07 [07]\n",
      "- 08 [08]\n",
      "- 09 [09]\n",
      "- 10 [10]\n",
      "- 11 [11]\n",
      "- 12 [12]\n",
      "eventyear:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- 2017 [2017]\n",
      "- 2016 [2016]\n",
      "- 2015 [2015]\n",
      "- 2014 [2014]\n",
      "- 2013 [2013]\n",
      "- 2012 [2012]\n",
      "- 2011 [2011]\n",
      "- 2010 [2010]\n",
      "- 2009 [2009]\n",
      "- 2008 [2008]\n",
      "- 2007 [2007]\n",
      "- 2006 [2006]\n",
      "- 2005 [2005]\n",
      "- 2004 [2004]\n",
      "- 2003 [2003]\n",
      "- 2002 [2002]\n",
      "- 2001 [2001]\n",
      "- 2000 [2000]\n",
      "- 1999 [1999]\n",
      "eventlocation:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- Aargau [RCH-AG]\n",
      "- Appenzell Innerhoden [RCH-AI]\n",
      "- Bern [RCH-BE]\n",
      "- Basel-Landschaft [RCH-BL]\n",
      "- Basel-Stadt [RCH-BS]\n",
      "- Fribourg [RCH-FR]\n",
      "- Geneva [RCH-GE]\n",
      "- Glarus [RCH-GL]\n",
      "- Graubünden [RCH-GR]\n",
      "- Lucerne [RCH-LU]\n",
      "- Neuchâtel [RCH-NE]\n",
      "- Nidwalden [RCH-NW]\n",
      "- Obwalden [RCH-OW]\n",
      "- St. Gallen [RCH-SG]\n",
      "- Schaffhausen [RCH-SH]\n",
      "- Solothurn [RCH-SO]\n",
      "- Schwyz [RCH-SZ]\n",
      "- Thurgau [RCH-TG]\n",
      "- Ticino [RCH-TI]\n",
      "- Uri [RCH-UR]\n",
      "- Vaud [RCH-VD]\n",
      "- Valais [RCH-VS]\n",
      "- Zug [RCH-ZG]\n",
      "- Zurich [RCH-ZH]\n",
      "- Vienna [RA-W]\n",
      "- Upper Austria [RA-O]\n",
      "- Salzburg [RA-SA]\n",
      "- Tyrol [RA-T]\n",
      "- Vorarlberg [RA-V]\n",
      "- Styria [RA-ST]\n",
      "- Carinthia [RA-K]\n",
      "- Baden-Württemberg [RD-BW]\n",
      "- Bavaria [RD-BY]\n",
      "- Berlin [RD-BE]\n",
      "- Hamburg [RD-HH]\n",
      "- Hesse [RD-HE]\n",
      "- Lower Saxony [RD-NI]\n",
      "- North Rhine-Westphalia [RD-NW]\n",
      "- Rhineland-Palatinate [RD-RP]\n",
      "- Saarland [RD-SL]\n",
      "- Saxony-Anhalt [RD-ST]\n",
      "- Schleswig-Holstein [RD-SH]\n",
      "- Franche-Comté [RF-I]\n",
      "- Languedoc-Roussillon [RF-K]\n",
      "- Nord - Pas-De-Calais [RF-O]\n",
      "- Poitou-Charentes [RF-T]\n",
      "- Rhône-Alpes [RF-V]\n",
      "- French Islands [RF-W]\n",
      "- Lombardy [RI-LOM]\n",
      "- Piedmont [RI-PMN]\n",
      "- Trentino South Tyrol [RI-TAA]\n",
      "- Veneto [RI-VEN]\n",
      "- Flevoland [RNL-FL]\n",
      "- Friesland [RNL-FR]\n",
      "- Gelderland [RNL-GE]\n",
      "- Groningen [RNL-GR]\n",
      "- Zuid Holland [RNL-ZH]\n",
      "- Blekinge län [RS-K]\n",
      "- Dalarnas län [RS-W]\n",
      "- Gotlands län [RS-I]\n",
      "- Örebro län [RS-T]\n",
      "- Västra Götalands län [RS-O]\n",
      "- ---- [all]\n",
      "- Austria [CA]\n",
      "- Belgium [CB]\n",
      "- Canada [CCAN]\n",
      "- France [CF]\n",
      "- Germany [CD]\n",
      "- Italy [CI]\n",
      "- Liechtenstein [CFL]\n",
      "- Norway [CN]\n",
      "- Switzerland [CCH]\n",
      "- United States [CUSA]\n"
     ]
    }
   ],
   "source": [
    "for s in selectors:\n",
    "    options = s.find_all('option')\n",
    "    options_desc_values = [(o.text, o.attrs['value']) for o in options]\n",
    "    print(s.attrs['name'] + ':')\n",
    "    for (d,v) in options_desc_values:\n",
    "        print(\"- {} [{}]\".format(d,v)) # more french"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get some data\n",
    "\n",
    "In order to get started, we can now start collecting the results from the Lausanne marathone, one of the main early event in Switzerland.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the html of the main page, and __extract the relevant parameters__ to query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of categories (age/sex/overall) in the main page: 119\n"
     ]
    }
   ],
   "source": [
    "laus_mar_url = 'https://services.datasport.com/2016/lauf/lamara/'\n",
    "result_html = rq.get(laus_mar_url)\n",
    "\n",
    "# use BS to get the categories in which the data is devided:\n",
    "\n",
    "result_soup = bs4.BeautifulSoup(result_html.text, \"lxml\")\n",
    "result_font = result_soup.find_all('font')\n",
    "\n",
    "print('number of categories (age/sex/overall) in the main page:', len(result_font))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marathon Dames Overall (220 classées)\n",
      "Semi Marathon Hommes Overall (2934 classés)\n",
      "Semi Marathon Dames Overall (1480 classées)\n",
      "10km Hommes Overall (2769 classés)\n",
      "10km Dames Overall (2747 classées)\n"
     ]
    }
   ],
   "source": [
    "# we look for the ones containing \n",
    "# '*** Overall ***', as they are the most general categories \n",
    "\n",
    "# this is indeed probably a GENERAL KEYWORD, as it's indeed found also in\n",
    "# events in other laungauges, \n",
    "# like https://services.datasport.com/2016/lauf/ascona-locarno-marathon/\n",
    "\n",
    "good_fonts_num = []\n",
    "\n",
    "for n_font, font in enumerate(result_font):\n",
    "    \n",
    "    if 'Overall' in font.findChild().get_text():\n",
    "            \n",
    "        good_fonts_num.append(n_font)\n",
    "        print(font.findChild().get_text())\n",
    "        \n",
    "        \n",
    "good_fonts_num = np.asarray(good_fonts_num)        \n",
    "        \n",
    "#  S***** -.- THERE IS A PROBLEM with the marathon hommes : \n",
    "# they are not in the same 'html shape' .. -.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  5,  7,  9, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_fonts_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we have to get all: href=RANG*** b\n",
    "\n",
    "rang_to_query = []\n",
    "\n",
    "for i in range(len(good_fonts_num)-1):\n",
    "        \n",
    "    my_font = result_font[good_fonts_num[i] + 1]\n",
    "    a_tag = my_font.find_all('a')\n",
    "    \n",
    "    for t in a_tag:\n",
    "    \n",
    "        if 'RANG' in t['href']:\n",
    "            \n",
    "            rang_to_query.append(t['href'])\n",
    "            \n",
    "#             print(t['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the datasport.com with the right parameters and finally get the __tables__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_url = \"https://services.datasport.com/2016/lauf/lamara\"\n",
    "full_url = base_url + '/' + rang_to_query[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_html = rq.get(full_url, params=rang_to_query[0])\n",
    "result_soup = bs4.BeautifulSoup(result_html.text, \"lxml\")\n",
    "\n",
    "data = result_soup.find_all('font')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to get the columns names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rang',\n",
       " 'nom',\n",
       " 'nat',\n",
       " 'an',\n",
       " 'lieu',\n",
       " 'équipe',\n",
       " 'pénalité',\n",
       " 'temps',\n",
       " 'retard',\n",
       " 'doss',\n",
       " 'cat/rang']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = data[0].get_text()\n",
    "col_list  = re.split(' +',col_list)[1:12]\n",
    "col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to get the rows:\n",
    "( we __neglet__: 'dossard', 'rank in his/her category', 'team', ....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(mind that the relevant info are in __data[2].contents[1,2,8]__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEL 1976 Bern 2:42.41,0 42-D40\n",
      "SUI 1972 Cernier 2:51.45,8 42-D40\n",
      "CRO 1976 CRO-Zagreb Maksimir 42-D40\n",
      "SUI 1969 GB-Penzance 2:53.43,2 42-D40\n",
      "SUI 1977 Ecublens ----- 42-D30\n",
      "FRA 1981 F-Lille METROPOLE 42-D30\n",
      "SUI 1986 Cheiry 3:08.08,4 42-D30\n",
      "SUI 1976 Portalban ----- 42-D40\n",
      "FRA 1990 F-Besancon val 42-D20\n",
      "ITA 1991 Genève Runners 42-D20\n",
      "FRA 1979 F-Marnay 3:17.45,2 42-D30\n",
      "SUI 1974 Zuchwil Langenthal 42-D40\n",
      "SUI 1981 Lausanne Ecublens 42-D30\n",
      "FRA 1972 F-Yvre MAMERS 42-D40\n",
      "BEL 1989 B-Bertrix 3:27.03,3 42-D20\n",
      "SUI 1978 Etoy 3:27.14,1 42-D30\n",
      "AUT 1983 Genève 3:27.33,6 42-D30\n",
      "SUI 1980 Bern 3:28.55,1 42-D30\n",
      "IRL 1993 Basel 3:34.19,1 42-D20\n",
      "SUI 1988 Zürich 3:35.23,6 42-D20\n",
      "FRA 1980 F-Montjean Loire 42-D30\n",
      "SUI 1991 Zürich 3:35.35,7 42-D20\n",
      "JPN 1954 J-Osaka Global 42-D60\n",
      "SUI 1972 Ringgenberg X-Bionic 42-D40\n",
      "SUI 1980 Lausanne 3:38.37,7 42-D30\n",
      "FRA 1990 F-Thonon Bains 42-D20\n",
      "SUI 1956 Gippingen 3:40.03,9 42-D60\n",
      "SUI 1969 Daillens ----- 42-D40\n",
      "SUI 1975 Rothenburg 3:40.36,9 42-D40\n",
      "SUI 1966 Le ----- 42-D50\n",
      "SUI 1978 Pully Boss 42-D30\n",
      "SUI 1979 Pully 3:41.07,6 42-D30\n",
      "SUI 1984 Val-d'Illiez 3:41.16,6 42-D30\n",
      "FRA 1976 F-Seynod Aidants 42-D40\n",
      "FRA 1984 F-Moutonne Lons 42-D30\n",
      "FRA 1986 F-Paris 3:41.59,4 42-D30\n",
      "SUI 1978 Poliez-le-Grand 10 42-D30\n",
      "FRA 1986 Chexbres 3:42.07,1 42-D30\n",
      "FRA 1972 Le ----- 42-D40\n",
      "FRA 1988 F-Annemasse 3:43.05,9 42-D20\n",
      "SUI 1983 Genève 3:43.06,8 42-D30\n",
      "FRA 1977 Lausanne 3:43.07,7 42-D30\n",
      "SUI 1976 Belp ----- 42-D40\n",
      "DEN 1965 DK-Jyllinge ----- 42-D50\n",
      "FRA 1967 F-Le Run&Freedom 42-D40\n",
      "SUI 1985 Lugnorre 3:45.29,8 42-D30\n",
      "GER 1969 D-Dossenheim Nikar 42-D40\n",
      "JPN 1985 USA-New NY 42-D30\n",
      "SUI 1953 Worb 3:47.10,9 42-D60\n",
      "SUI 1991 Lausanne 3:47.11,3 42-D20\n",
      "FRA 1980 F-Choisy Brie 42-D30\n",
      "FRA 1989 F-Bordeaux 3:47.46,1 42-D20\n",
      "RUS 1982 F-Paris 3:48.13,1 42-D30\n",
      "POL 1975 Lausanne France/KLM 42-D40\n",
      "SUI 1976 La SA 42-D40\n",
      "SUI 1979 Renens Proches 42-D30\n",
      "SUI 1974 Vex 3:50.23,4 42-D40\n",
      "FRA 1971 F-Champigny Marne 42-D40\n",
      "BEL 1993 B-Hamme ----- 42-D20\n",
      "AUT 1978 A-Feldkirch 3:51.10,9 42-D30\n",
      "FRA 1976 F-Champanges 3:52.06,9 42-D40\n",
      "FRA 1987 D-Stuttgart Sport 42-D20\n",
      "SUI 1986 Bern ----- 42-D30\n",
      "SUI 1976 Trélex Aidants 42-D40\n",
      "BEL 1965 B-Sint-Martens-Latem 3:52.29,7 42-D50\n",
      "FRA 1971 F-Montesson Runners 42-D40\n",
      "SUI 1983 Cortaillod 3:53.54,3 42-D30\n",
      "GER 1959 D-Kiel Kiel 42-D50\n",
      "SUI 1986 Basel 3:54.19,6 42-D30\n",
      "SUI 1970 Thun 3:54.26,8 42-D40\n",
      "FRA 1975 F-Jarnac 3:54.51,2 42-D40\n",
      "FRA 1974 F-Tassin Demi 42-D40\n",
      "SUI 1970 Habsburg 3:55.56,1 42-D40\n",
      "FRA 1981 F-Ferney ----- 42-D30\n",
      "ESP 1980 Neuchâtel 3:56.57,5 42-D30\n",
      "FRA 1973 F-Sault ----- 42-D40\n",
      "SUI 1971 F-Bians Usiers 42-D40\n",
      "SUI 1985 Wettingen 3:58.35,3 42-D30\n",
      "SWE 1992 Lausanne Sciences 42-D20\n",
      "FRA 1972 F-Sailly Lannoy 42-D40\n",
      "SUI 1997 Worb 3:59.00,8 42-JunF\n",
      "FRA 1982 F-Achenheim 3:59.11,0 42-D30\n",
      "SUI 1972 Maisprach 3:59.26,4 42-D40\n",
      "SUI 1981 Neuenegg 3:59.31,1 42-D30\n",
      "SUI 1970 Wangen Olten 42-D40\n",
      "SUI 1972 Soulce 4:00.37,2 42-D40\n",
      "FIN 1984 GB-London Maratonmatkat 42-D30\n",
      "FRA 1979 F-Paris 4:01.43,4 42-D30\n",
      "SUI 1971 F-Russange 4:01.52,2 42-D40\n",
      "SUI 1984 Corbeyrier 4:02.43,6 42-D30\n",
      "SUI 1985 Bern 4:03.04,8 42-D30\n",
      "GER 1980 D-Berlin 4:03.51,0 42-D30\n",
      "FRA 1991 F-Dijon Shop 42-D20\n",
      "SUI 1993 Epalinges 4:04.20,0 42-D20\n",
      "VEN 1985 Neuchâtel 4:05.15,3 42-D30\n",
      "SUI 1987 Gampelen 4:05.16,7 42-D20\n",
      "SUI 1982 Villarepos 4:05.43,0 42-D30\n",
      "SUI 1988 St-Luc 4:06.16,7 42-D20\n",
      "FRA 1969 F-La Calvisson 42-D40\n",
      "CZE 1963 CZ-Kladno 4:07.35,2 42-D50\n",
      "SUI 1991 Biel/Bienne 4:07.49,6 42-D20\n",
      "SUI 1971 L'Isle BCV 42-D40\n",
      "SWE 1985 S-Stockholm 4:08.49,2 42-D30\n",
      "GBR 1972 Belfaux Running 42-D40\n",
      "CHN 1967 THA-Suan Bangkok 42-D40\n",
      "ITA 1987 Genève ----- 42-D20\n",
      "FRA 1982 F-Cluses Philippe 42-D30\n",
      "FRA 1989 F-Reims 4:12.09,2 42-D20\n",
      "BEL 1974 B-Wemmel 4:12.12,8 42-D40\n",
      "SUI 1982 Lausanne 4:12.48,2 42-D30\n",
      "SUI 1986 Zürich France/KLM 42-D30\n",
      "SUI 1994 Burgdorf 4:13.43,8 42-D20\n",
      "GBR 1989 Vernier 4:13.45,2 42-D20\n",
      "BEL 1967 B-Fontaine-l'Evêque athlétisme 42-D40\n",
      "FRA 1981 F-Le Run&Freedom 42-D30\n",
      "CAN 1986 Grandvillard 4:14.33,8 42-D30\n",
      "FRA 1975 F-Bornay 4:14.43,1 42-D40\n",
      "GBR 1958 La ----- 42-D50\n",
      "SUI 1989 Horgen 4:17.38,9 42-D20\n",
      "FRA 1958 F-Maille 4:18.04,6 42-D50\n",
      "FRA 1972 F-Moulins 4:19.19,6 42-D40\n",
      "SUI 1976 Winterthur 4:20.28,6 42-D40\n",
      "FRA 1988 F-Paris 4:21.02,3 42-D20\n",
      "FRA 1991 F-Nozay 4:21.35,4 42-D20\n",
      "CAN 1983 Genève 4:22.24,3 42-D30\n",
      "FRA 1972 F-Montigny Metz 42-D40\n",
      "FRA 1987 F-Douvaine 4:23.07,4 42-D20\n",
      "BEL 1969 Coppet ----- 42-D40\n",
      "FRA 1994 F-Aix Bains 42-D20\n",
      "SUI 1963 Ferreyres 4:24.06,9 42-D50\n",
      "BEL 1972 B-Wezembeek-Oppem 4:24.44,1 42-D40\n",
      "SUI 1983 St-Prex 4:24.57,8 42-D30\n",
      "ITA 1983 Liestal 4:25.37,0 42-D30\n",
      "FRA 1961 F-Paris 4:25.50,2 42-D50\n",
      "SUI 1987 Montreux 4:26.24,1 42-D20\n",
      "SUI 1969 Cossonay-Ville Aidants 42-D40\n",
      "SUI 1964 Utzenstorf 4:27.15,5 42-D50\n",
      "FRA 1954 F-Balma 4:28.08,2 42-D60\n",
      "FRA 1967 F-Balma 4:28.09,3 42-D40\n",
      "GBR 1992 GB-Campbeltown 4:28.10,9 42-D20\n",
      "SUI 1987 Ecublens EPFL 42-D20\n",
      "SUI 1964 Bofflens Club 42-D50\n",
      "FRA 1970 F-Varces et 42-D40\n",
      "SWE 1981 S-Stockholm 4:30.30,9 42-D30\n",
      "FRA 1992 F-St en 42-D20\n",
      "SUI 1959 Neyruz smrun 42-D50\n",
      "SUI 1973 Chavannes-de-Bogis 4:31.33,9 42-D40\n",
      "SUI 1978 Aigle Running 42-D30\n",
      "FRA 1965 F-Yerres 4:32.20,5 42-D50\n",
      "GER 1958 D-Rostock 4:33.22,3 42-D50\n",
      "SUI 1982 Morges Running 42-D30\n",
      "FRA 1971 F-Seine ----- 42-D40\n",
      "FRA 1976 Préverenges Team 42-D40\n",
      "SUI 1989 Lausanne ----- 42-D20\n",
      "FRA 1983 Lonay ----- 42-D30\n",
      "GBR 1961 GB-Bristol 4:35.53,8 42-D50\n",
      "POL 1986 Prilly ----- 42-D30\n",
      "FRA 1983 F-Allinges THONON 42-D30\n",
      "FRA 1988 F-Amphion Bains 42-D20\n",
      "SUI 1966 Lausanne 4:36.49,9 42-D50\n",
      "FRA 1971 F-Bourg Bresse 42-D40\n",
      "ESP 1976 Lonay Sciences 42-D40\n",
      "UKR 1984 Lausanne 4:37.22,4 42-D30\n",
      "FIN 1987 FI-Espoo Maratonmatkat 42-D20\n",
      "FRA 1968 F-Amberieu Bugey 42-D40\n",
      "FRA 1983 F-Etaules des 42-D30\n",
      "FRA 1970 F-Strasbourg 4:38.40,5 42-D40\n",
      "FRA 1969 F-Le Run&Freedom 42-D40\n",
      "SWE 1979 GB-Bexleyheath 4:38.47,7 42-D30\n",
      "SUI 1969 F-Lans 4:38.58,8 42-D40\n",
      "GER 1985 F-Ferney ----- 42-D30\n",
      "RUS 1988 Lausanne 4:39.08,7 42-D20\n",
      "SUI 1985 Felsberg 4:39.13,3 42-D30\n",
      "SUI 1974 Gorgier 4:39.44,3 42-D40\n",
      "MAS 1946 Dietikon 4:40.51,2 42-D70\n",
      "BRA 1971 La (Lutry) 42-D40\n",
      "SUI 1989 Lausanne ----- 42-D20\n",
      "USA 1992 Morges 4:43.22,6 42-D20\n",
      "FRA 1974 F-Champanges 4:43.35,1 42-D40\n",
      "SUI 1969 F-Varces et 42-D40\n",
      "SUI 1980 Morges 4:47.15,1 42-D30\n",
      "JPN 1959 J-Hyogo Global 42-D50\n",
      "FRA 1958 F-St des 42-D50\n",
      "SUI 1965 Orges 4:49.32,3 42-D50\n",
      "FRA 1971 F-Chambery 4:51.28,3 42-D40\n",
      "ROM 1985 R-Bucharest 4:54.43,1 42-D30\n",
      "JPN 1962 J-Kanagawa Global 42-D50\n",
      "JPN 1957 J-Hyogo Global 42-D50\n",
      "GBR 1958 GB-Kingston Thames 42-D50\n",
      "SUI 1976 Genève France/KLM 42-D40\n",
      "SUI 1965 F-Annecy Vieux 42-D50\n",
      "NOR 1989 N-Randaberg 4:56.32,8 42-D20\n",
      "UKR 1986 Lausanne 4:58.27,6 42-D30\n",
      "LUX 1961 L-Howald 5:01.27,4 42-D50\n",
      "CAN 1986 CAN-Niagara Geneva 42-D30\n",
      "LUX 1968 L-Eischen 5:05.20,9 42-D40\n",
      "SUI 1988 Chavannes-près-Renens 5:05.52,6 42-D20\n",
      "SUI 1995 Poliez-Pittet 5:06.14,7 42-D20\n",
      "GBR 1980 Prilly 5:07.07,8 42-D30\n",
      "FRA 1969 F-Belfort France/KLM 42-D40\n",
      "SUI 1994 Epalinges ----- 42-D20\n",
      "FRA 1967 F-Le courir 42-D40\n",
      "FRA 1977 F-Paris 5:15.50,4 42-D30\n",
      "FRA 1955 F-Nogent Marne 42-D60\n",
      "FRA 1971 F-Nointot 5:22.01,0 42-D40\n",
      "ITA 1991 Vallorbe 5:25.14,8 42-D20\n",
      "FRA 1964 F-Thoraise 5:25.18,0 42-D50\n",
      "BEL 1976 B-Thy-le-Château 5:25.38,6 42-D40\n",
      "FRA 1988 F-Brochon 5:26.19,6 42-D20\n",
      "SUI 1967 Le ----- 42-D40\n",
      "SUI 1990 Rapperswil ----- 42-D20\n",
      "JPN 1962 J-Higashi-Osaka-shi 5:33.14,5 42-D50\n",
      "FRA 1968 F-Collonges-sous-Salève 5:37.27,1 42-D40\n",
      "SUI 1973 F-Ferney ----- 42-D40\n",
      "GER 1966 D-Potsdam Potsdam 42-D50\n",
      "GBR 1978 F-Bozel 5:52.39,0 42-D30\n",
      "JPN 1992 J-Bunkyo-ku ----- 42-D20\n",
      "FRA 1990 F-Servas 6:02.04,6 42-D20\n",
      "JPN 1940 J-Fukuoka-Shi Global 42-D70\n",
      "FRA 1956 F-Trouville Mer 42-D60\n"
     ]
    }
   ],
   "source": [
    "# rows =  data[2].find_all('span')\n",
    "# len(rows)\n",
    "\n",
    "for i in range(len(data[2].contents)//8):\n",
    "    \n",
    "    \n",
    "    name = data[2].contents[8*i+1].get_text()\n",
    "\n",
    "    country_age_city_time = re.split(' +',data[2].contents[8*i+2])\n",
    "\n",
    "    country = country_age_city_time[1]\n",
    "    age = country_age_city_time[2]\n",
    "    city = country_age_city_time[3]\n",
    "    tot_time = country_age_city_time[5]\n",
    "\n",
    "    cat_catrank = re.split(' +',data[2].contents[8*i+8].split('¦')[0])\n",
    "    category = cat_catrank[1] # we keep only the age/sex category\n",
    "    \n",
    "    print(country,age,city,tot_time,category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ******* ******* ******* ******* *******  \n",
    "# OLD CODE \n",
    "# ******* ******* ******* ******* ******* ******* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_html(result_table.decode())[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = df.loc[1]                # use row 2 as column names\n",
    "df = df.drop([0, 1])                  # drop useless first rows\n",
    "df = df.drop([np.nan], axis=1)        # drop useless nan column\n",
    "df.index = df['No Sciper']            # use sciper column as index\n",
    "\n",
    "# Drop some columns\n",
    "df = df.drop(['Orientation Bachelor', 'Orientation Master', 'Filière opt.', 'Type Echange', 'Ecole Echange'], axis=1)\n",
    "\n",
    "# Do some renaming\n",
    "df.index.name = 'sciper'\n",
    "df.columns = ['gender', 'full_name', 'specialization', 'minor', 'status', 'sciper']\n",
    "\n",
    "# Map gender to more standard names\n",
    "dict_gender = {'Monsieur': 'male','Madame': 'female'}\n",
    "df.gender.replace(dict_gender, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tools\n",
    "\n",
    "We can define a helper function which, given a base URL and a dictionary of parameters, will fetch the data and fill a DataFrame with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(base_url, params_dict):\n",
    "    \"\"\"Get data from IS-Academia in a pandas DataFrame\"\"\"\n",
    "    \n",
    "    # Same sequence of operations of above, with a check if the result_table is empty\n",
    "    \n",
    "    result_html = rq.get(base_url,params=params_dict)\n",
    "    result_soup = bs4.BeautifulSoup(result_html.text, \"lxml\")\n",
    "    result_table = result_soup.find_all('table')[0]\n",
    "    \n",
    "    if (result_table.text == ''):\n",
    "        # Return empty dataframe\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        # Build a DataFrame containing the data, with SCIPER as index\n",
    "        df = pd.read_html(result_table.decode())[0]\n",
    "        try:\n",
    "            df.columns = df.loc[1]                # use 2nd row as column names\n",
    "            df = df.drop([0, 1])                  # drop useless first rows\n",
    "            df = df.drop([np.nan], axis=1)        # drop useless nan column\n",
    "            df.index = df['No Sciper']            # use sciper column as index\n",
    "        \n",
    "            # Drop some columns\n",
    "            df = df.drop(['Orientation Bachelor', 'Orientation Master', 'Filière opt.', 'Type Echange', 'Ecole Echange'], axis=1)\n",
    "            # Do some renaming\n",
    "            df.index.name = 'sciper'\n",
    "            df.columns = ['gender', 'full_name', 'specialization', 'minor', 'status', 'sciper']\n",
    "            # Map gender to more standard names\n",
    "            dict_gender = {'Monsieur': 'male','Madame': 'female'}\n",
    "            df.gender.replace(dict_gender, inplace=True)\n",
    "        except:\n",
    "            df = pd.DataFrame()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines test this function with hardcoded values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_url = \"http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.html?\"\n",
    "params_dict = {\n",
    "    'ww_x_GPS': 2021043255,\n",
    "    'ww_i_reportModel': 133685247,\n",
    "    'ww_i_reportModelXsl': 133685270,\n",
    "    'ww_x_UNITE_ACAD': 249847,\n",
    "    'ww_x_PERIODE_ACAD': 355925344,\n",
    "    'ww_x_PERIODE_PEDAGO': 249108,\n",
    "    'ww_x_HIVERETE':2936286\n",
    "}\n",
    "\n",
    "get_data(base_url, params_dict).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's get all the possible values in a cleaner way and keep them in variables that we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acad_period = {}\n",
    "level = {}\n",
    "semester = {}\n",
    "acad_unit = {}\n",
    "\n",
    "for s in selectors:\n",
    "    options = s.find_all('option')\n",
    "    options_desc_values = [(o.text, o.attrs['value']) for o in options]\n",
    "    s_name = s.attrs['name']\n",
    "    choices = {d: int(v) for (d,v) in options_desc_values if d!=''}\n",
    "    \n",
    "    if s_name == 'ww_x_PERIODE_ACAD':\n",
    "        acad_period = choices\n",
    "    elif s_name == 'ww_x_PERIODE_PEDAGO':\n",
    "        level = choices\n",
    "    elif s_name == 'ww_x_HIVERETE':\n",
    "        for (d,v) in options_desc_values:\n",
    "            if 'automne' in d:\n",
    "                semester['automne'] = int(v)\n",
    "            elif 'printemps' in d:\n",
    "                semester['printemps'] =int(v)\n",
    "    elif s_name == 'ww_x_UNITE_ACAD':\n",
    "        acad_unit = choices\n",
    "\n",
    "# Example of result\n",
    "acad_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get bachelor data for every year and store it if it's not empty\n",
    "import os\n",
    "local_dir = '.local-data'\n",
    "try:\n",
    "    os.mkdir(local_dir)\n",
    "except FileExistsError:\n",
    "    # directory exists\n",
    "    print(\"Using existing '\" + local_dir + \"' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fixed values\n",
    "params_dict = {\n",
    "    'ww_x_GPS': -1,\n",
    "    'ww_i_reportModel': 133685247,\n",
    "    'ww_i_reportModelXsl': 133685270,\n",
    "    'ww_x_UNITE_ACAD': acad_unit['Informatique']\n",
    "}\n",
    "\n",
    "# Iterate over all the varying params and keep only data for bachelors\n",
    "for year_key, year_value in acad_period.items():\n",
    "    for level_key, level_value in level.items():\n",
    "        for semester_key, semester_value in semester.items():\n",
    "            if 'bachelor' in level_key.lower():\n",
    "                params_dict['ww_x_PERIODE_ACAD'] = year_value\n",
    "                params_dict['ww_x_PERIODE_PEDAGO'] = level_value\n",
    "                params_dict['ww_x_HIVERETE'] = semester_value\n",
    "                \n",
    "                df = get_data(base_url, params_dict)\n",
    "                if not df.empty:\n",
    "                    # Persist dataframe locally with pickle\n",
    "                    filename = year_key + '-' + level_key.replace(' ', '-').lower() + '-' + semester_key\n",
    "                    df.to_pickle(local_dir + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the previous cell should download 60 files!, as you can check with this command:\n",
    "print(len([name for name in os.listdir(local_dir)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hereby show an example of dataframe laoded from the files previously download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_example = pd.read_pickle(local_dir + '/2007-2008-bachelor-semestre-6-printemps')\n",
    "df_example.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
