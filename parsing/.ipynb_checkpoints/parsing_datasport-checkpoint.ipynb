{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Data from [datasport.com](https://www.datasport.com/en/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use postman to understand the parameters used by the url request, asked for the exercise.\n",
    "\n",
    "(However, notice that there are equivalent tools for other browser - for instance, for firefox:\n",
    "http://stackoverflow.com/questions/28997326/postman-addons-like-in-firefox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important modules for this HW\n",
    "import bs4 # doc: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "import requests as rq \n",
    "import re\n",
    "\n",
    "# previous useful modules\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form_source = rq.get(\"https://www.datasport.com/en/\")\n",
    "form_soup = bs4.BeautifulSoup(form_source.text, \"html.parser\")\n",
    "# print(form_soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the `select` menus of the page, using the `find_all` method of *BeautifulSoup* which allows to search for all tags of a certain type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "selectors = form_soup.find_all('select')\n",
    "print(len(selectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most importantly, we can find out what each tag is about by printing the its `name` attribute :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select n°0 : etyp\n",
      "Select n°1 : eventmonth\n",
      "Select n°2 : eventyear\n",
      "Select n°3 : eventlocation\n"
     ]
    }
   ],
   "source": [
    "for num, s in enumerate(selectors):\n",
    "    print(\"Select n°{} : {}\".format(num, s.attrs['name'])) # wild french appears..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etyp:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- Cross-Country-Skiing [Cross-Country-Skiing]\n",
      "- Cycling [Cycling]\n",
      "- Cycling,MTB [Cycling,MTB]\n",
      "- Cycling,Others [Cycling,Others]\n",
      "- Duathlon [Duathlon]\n",
      "- Inline [Inline]\n",
      "- MTB [MTB]\n",
      "- MTB,Cycling [MTB,Cycling]\n",
      "- MTB,Cycling,Others [MTB,Cycling,Others]\n",
      "- MTB,Others [MTB,Others]\n",
      "- MTB,X-Hours [MTB,X-Hours]\n",
      "- Others [Others]\n",
      "- Others,Inline,Running,MTB [Others,Inline,Running,MTB]\n",
      "- Running [Running]\n",
      "- Running,Inline [Running,Inline]\n",
      "- Running,MTB [Running,MTB]\n",
      "- Running,MTB,Others [Running,MTB,Others]\n",
      "- Running,Skiing/Snowboard [Running,Skiing/Snowboard]\n",
      "- Running,Waffenlauf [Running,Waffenlauf]\n",
      "- Running,Walking [Running,Walking]\n",
      "- Running,Walking,MTB [Running,Walking,MTB]\n",
      "- Running,Walking,Others [Running,Walking,Others]\n",
      "- Running,X-Hours [Running,X-Hours]\n",
      "- Skiing/Snowboard [Skiing/Snowboard]\n",
      "- Triathlon [Triathlon]\n",
      "- Triathlon,Duathlon [Triathlon,Duathlon]\n",
      "- Triathlon,Others [Triathlon,Others]\n",
      "- Waffenlauf [Waffenlauf]\n",
      "- Walking [Walking]\n",
      "- X-Hours [X-Hours]\n",
      "- X-Hours,MTB [X-Hours,MTB]\n",
      "eventmonth:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- 01 [01]\n",
      "- 02 [02]\n",
      "- 03 [03]\n",
      "- 04 [04]\n",
      "- 05 [05]\n",
      "- 06 [06]\n",
      "- 07 [07]\n",
      "- 08 [08]\n",
      "- 09 [09]\n",
      "- 10 [10]\n",
      "- 11 [11]\n",
      "- 12 [12]\n",
      "eventyear:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- 2017 [2017]\n",
      "- 2016 [2016]\n",
      "- 2015 [2015]\n",
      "- 2014 [2014]\n",
      "- 2013 [2013]\n",
      "- 2012 [2012]\n",
      "- 2011 [2011]\n",
      "- 2010 [2010]\n",
      "- 2009 [2009]\n",
      "- 2008 [2008]\n",
      "- 2007 [2007]\n",
      "- 2006 [2006]\n",
      "- 2005 [2005]\n",
      "- 2004 [2004]\n",
      "- 2003 [2003]\n",
      "- 2002 [2002]\n",
      "- 2001 [2001]\n",
      "- 2000 [2000]\n",
      "- 1999 [1999]\n",
      "eventlocation:\n",
      "- All [all]\n",
      "- ---- [all]\n",
      "- Aargau [RCH-AG]\n",
      "- Appenzell Innerhoden [RCH-AI]\n",
      "- Bern [RCH-BE]\n",
      "- Basel-Landschaft [RCH-BL]\n",
      "- Basel-Stadt [RCH-BS]\n",
      "- Fribourg [RCH-FR]\n",
      "- Geneva [RCH-GE]\n",
      "- Glarus [RCH-GL]\n",
      "- Graubünden [RCH-GR]\n",
      "- Lucerne [RCH-LU]\n",
      "- Neuchâtel [RCH-NE]\n",
      "- Nidwalden [RCH-NW]\n",
      "- Obwalden [RCH-OW]\n",
      "- St. Gallen [RCH-SG]\n",
      "- Schaffhausen [RCH-SH]\n",
      "- Solothurn [RCH-SO]\n",
      "- Schwyz [RCH-SZ]\n",
      "- Thurgau [RCH-TG]\n",
      "- Ticino [RCH-TI]\n",
      "- Uri [RCH-UR]\n",
      "- Vaud [RCH-VD]\n",
      "- Valais [RCH-VS]\n",
      "- Zug [RCH-ZG]\n",
      "- Zurich [RCH-ZH]\n",
      "- Vienna [RA-W]\n",
      "- Upper Austria [RA-O]\n",
      "- Salzburg [RA-SA]\n",
      "- Tyrol [RA-T]\n",
      "- Vorarlberg [RA-V]\n",
      "- Styria [RA-ST]\n",
      "- Carinthia [RA-K]\n",
      "- Baden-Württemberg [RD-BW]\n",
      "- Bavaria [RD-BY]\n",
      "- Berlin [RD-BE]\n",
      "- Hamburg [RD-HH]\n",
      "- Hesse [RD-HE]\n",
      "- Lower Saxony [RD-NI]\n",
      "- North Rhine-Westphalia [RD-NW]\n",
      "- Rhineland-Palatinate [RD-RP]\n",
      "- Saarland [RD-SL]\n",
      "- Saxony-Anhalt [RD-ST]\n",
      "- Schleswig-Holstein [RD-SH]\n",
      "- Franche-Comté [RF-I]\n",
      "- Languedoc-Roussillon [RF-K]\n",
      "- Nord - Pas-De-Calais [RF-O]\n",
      "- Poitou-Charentes [RF-T]\n",
      "- Rhône-Alpes [RF-V]\n",
      "- French Islands [RF-W]\n",
      "- Lombardy [RI-LOM]\n",
      "- Piedmont [RI-PMN]\n",
      "- Trentino South Tyrol [RI-TAA]\n",
      "- Veneto [RI-VEN]\n",
      "- Flevoland [RNL-FL]\n",
      "- Friesland [RNL-FR]\n",
      "- Gelderland [RNL-GE]\n",
      "- Groningen [RNL-GR]\n",
      "- Zuid Holland [RNL-ZH]\n",
      "- Blekinge län [RS-K]\n",
      "- Dalarnas län [RS-W]\n",
      "- Gotlands län [RS-I]\n",
      "- Örebro län [RS-T]\n",
      "- Västra Götalands län [RS-O]\n",
      "- ---- [all]\n",
      "- Austria [CA]\n",
      "- Belgium [CB]\n",
      "- Canada [CCAN]\n",
      "- France [CF]\n",
      "- Germany [CD]\n",
      "- Italy [CI]\n",
      "- Liechtenstein [CFL]\n",
      "- Norway [CN]\n",
      "- Switzerland [CCH]\n",
      "- United States [CUSA]\n"
     ]
    }
   ],
   "source": [
    "for s in selectors:\n",
    "    options = s.find_all('option')\n",
    "    options_desc_values = [(o.text, o.attrs['value']) for o in options]\n",
    "    print(s.attrs['name'] + ':')\n",
    "    for (d,v) in options_desc_values:\n",
    "        print(\"- {} [{}]\".format(d,v)) # more french"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get some data\n",
    "\n",
    "In order to get started, we can now start collecting the results from the Lausanne marathone, one of the main early event in Switzerland.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the html of the main page, and __extract the relevant parameters__ to query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of categories (age/sex/overall) in the main page: 119\n"
     ]
    }
   ],
   "source": [
    "laus_mar_url = 'https://services.datasport.com/2016/lauf/lamara/'\n",
    "result_html = rq.get(laus_mar_url)\n",
    "\n",
    "# use BS to get the categories in which the data is devided:\n",
    "\n",
    "result_soup = bs4.BeautifulSoup(result_html.text, \"lxml\")\n",
    "result_font = result_soup.find_all('font')\n",
    "\n",
    "print('number of categories (age/sex/overall) in the main page:', len(result_font))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marathon Dames Overall (220 classées)\n",
      "Semi Marathon Hommes Overall (2934 classés)\n",
      "Semi Marathon Dames Overall (1480 classées)\n",
      "10km Hommes Overall (2769 classés)\n",
      "10km Dames Overall (2747 classées)\n"
     ]
    }
   ],
   "source": [
    "# we look for the ones containing \n",
    "# '*** Overall ***', as they are the most general categories \n",
    "\n",
    "# this is indeed probably a GENERAL KEYWORD, as it's indeed found also in\n",
    "# events in other laungauges, \n",
    "# like https://services.datasport.com/2016/lauf/ascona-locarno-marathon/\n",
    "\n",
    "good_fonts_num = []\n",
    "\n",
    "for n_font, font in enumerate(result_font):\n",
    "    \n",
    "    if 'Overall' in font.findChild().get_text():\n",
    "            \n",
    "        good_fonts_num.append(n_font)\n",
    "        print(font.findChild().get_text())\n",
    "        \n",
    "        \n",
    "good_fonts_num = np.asarray(good_fonts_num)        \n",
    "        \n",
    "#  S***** -.- THERE IS A PROBLEM with the marathon hommes : \n",
    "# they are not in the same 'html shape' .. -.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  5,  7,  9, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_fonts_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we have to get all: href=RANG*** b\n",
    "\n",
    "rang_to_query = []\n",
    "\n",
    "for i in range(len(good_fonts_num)-1):\n",
    "        \n",
    "    my_font = result_font[good_fonts_num[i] + 1]\n",
    "    a_tag = my_font.find_all('a')\n",
    "    \n",
    "    for t in a_tag:\n",
    "    \n",
    "        if 'RANG' in t['href']:\n",
    "            \n",
    "            rang_to_query.append(t['href'])\n",
    "            \n",
    "#             print(t['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the datasport.com with the right parameters and finally get the __tables__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_url = \"https://services.datasport.com/2016/lauf/lamara\"\n",
    "full_url = base_url + '/' + rang_to_query[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_html = rq.get(full_url, params=rang_to_query[0])\n",
    "result_soup = bs4.BeautifulSoup(result_html.text, \"lxml\")\n",
    "\n",
    "data = result_soup.find_all('font')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to get the columns names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rang',\n",
       " 'nom',\n",
       " 'nat',\n",
       " 'an',\n",
       " 'lieu',\n",
       " 'équipe',\n",
       " 'pénalité',\n",
       " 'temps',\n",
       " 'retard',\n",
       " 'doss',\n",
       " 'cat/rang']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = data[0].get_text()\n",
    "col_list  = re.split(' +',col_list)[1:12]\n",
    "col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to get the rows:\n",
    "( we __neglet__: 'dossard', 'rank in his/her category', 'team', ....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(mind that the relevant info are in __data[2].contents[1,2,8]__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-7e86688c65e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcountry_age_city_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' +'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lazzari/anaconda/envs/py3k/lib/python3.5/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    728\u001b[0m             raise AttributeError(\n\u001b[1;32m    729\u001b[0m                 \"'%s' object has no attribute '%s'\" % (\n\u001b[0;32m--> 730\u001b[0;31m                     self.__class__.__name__, attr))\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moutput_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "# rows =  data[2].find_all('span')\n",
    "# len(rows)\n",
    "\n",
    "for i in range(len(data[2].contents)//8):\n",
    "    \n",
    "    \n",
    "    name = data[2].contents[8*i+1].get_text()\n",
    "\n",
    "    country_age_city_time = re.split(' +',data[2].contents[8*i+2])\n",
    "\n",
    "    country = country_age_city_time[1]\n",
    "    age = country_age_city_time[2]\n",
    "    city = country_age_city_time[3]\n",
    "    tot_time = country_age_city_time[5]\n",
    "\n",
    "    cat_catrank = re.split(' +',data[2].contents[8*i+8].split('¦')[0])\n",
    "    category = cat_catrank[1] # we keep only the age/sex category "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ******* ******* ******* ******* *******  \n",
    "# OLD CODE \n",
    "# ******* ******* ******* ******* ******* ******* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_html(result_table.decode())[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = df.loc[1]                # use row 2 as column names\n",
    "df = df.drop([0, 1])                  # drop useless first rows\n",
    "df = df.drop([np.nan], axis=1)        # drop useless nan column\n",
    "df.index = df['No Sciper']            # use sciper column as index\n",
    "\n",
    "# Drop some columns\n",
    "df = df.drop(['Orientation Bachelor', 'Orientation Master', 'Filière opt.', 'Type Echange', 'Ecole Echange'], axis=1)\n",
    "\n",
    "# Do some renaming\n",
    "df.index.name = 'sciper'\n",
    "df.columns = ['gender', 'full_name', 'specialization', 'minor', 'status', 'sciper']\n",
    "\n",
    "# Map gender to more standard names\n",
    "dict_gender = {'Monsieur': 'male','Madame': 'female'}\n",
    "df.gender.replace(dict_gender, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tools\n",
    "\n",
    "We can define a helper function which, given a base URL and a dictionary of parameters, will fetch the data and fill a DataFrame with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(base_url, params_dict):\n",
    "    \"\"\"Get data from IS-Academia in a pandas DataFrame\"\"\"\n",
    "    \n",
    "    # Same sequence of operations of above, with a check if the result_table is empty\n",
    "    \n",
    "    result_html = rq.get(base_url,params=params_dict)\n",
    "    result_soup = bs4.BeautifulSoup(result_html.text, \"lxml\")\n",
    "    result_table = result_soup.find_all('table')[0]\n",
    "    \n",
    "    if (result_table.text == ''):\n",
    "        # Return empty dataframe\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        # Build a DataFrame containing the data, with SCIPER as index\n",
    "        df = pd.read_html(result_table.decode())[0]\n",
    "        try:\n",
    "            df.columns = df.loc[1]                # use 2nd row as column names\n",
    "            df = df.drop([0, 1])                  # drop useless first rows\n",
    "            df = df.drop([np.nan], axis=1)        # drop useless nan column\n",
    "            df.index = df['No Sciper']            # use sciper column as index\n",
    "        \n",
    "            # Drop some columns\n",
    "            df = df.drop(['Orientation Bachelor', 'Orientation Master', 'Filière opt.', 'Type Echange', 'Ecole Echange'], axis=1)\n",
    "            # Do some renaming\n",
    "            df.index.name = 'sciper'\n",
    "            df.columns = ['gender', 'full_name', 'specialization', 'minor', 'status', 'sciper']\n",
    "            # Map gender to more standard names\n",
    "            dict_gender = {'Monsieur': 'male','Madame': 'female'}\n",
    "            df.gender.replace(dict_gender, inplace=True)\n",
    "        except:\n",
    "            df = pd.DataFrame()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines test this function with hardcoded values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_url = \"http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.html?\"\n",
    "params_dict = {\n",
    "    'ww_x_GPS': 2021043255,\n",
    "    'ww_i_reportModel': 133685247,\n",
    "    'ww_i_reportModelXsl': 133685270,\n",
    "    'ww_x_UNITE_ACAD': 249847,\n",
    "    'ww_x_PERIODE_ACAD': 355925344,\n",
    "    'ww_x_PERIODE_PEDAGO': 249108,\n",
    "    'ww_x_HIVERETE':2936286\n",
    "}\n",
    "\n",
    "get_data(base_url, params_dict).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's get all the possible values in a cleaner way and keep them in variables that we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acad_period = {}\n",
    "level = {}\n",
    "semester = {}\n",
    "acad_unit = {}\n",
    "\n",
    "for s in selectors:\n",
    "    options = s.find_all('option')\n",
    "    options_desc_values = [(o.text, o.attrs['value']) for o in options]\n",
    "    s_name = s.attrs['name']\n",
    "    choices = {d: int(v) for (d,v) in options_desc_values if d!=''}\n",
    "    \n",
    "    if s_name == 'ww_x_PERIODE_ACAD':\n",
    "        acad_period = choices\n",
    "    elif s_name == 'ww_x_PERIODE_PEDAGO':\n",
    "        level = choices\n",
    "    elif s_name == 'ww_x_HIVERETE':\n",
    "        for (d,v) in options_desc_values:\n",
    "            if 'automne' in d:\n",
    "                semester['automne'] = int(v)\n",
    "            elif 'printemps' in d:\n",
    "                semester['printemps'] =int(v)\n",
    "    elif s_name == 'ww_x_UNITE_ACAD':\n",
    "        acad_unit = choices\n",
    "\n",
    "# Example of result\n",
    "acad_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get bachelor data for every year and store it if it's not empty\n",
    "import os\n",
    "local_dir = '.local-data'\n",
    "try:\n",
    "    os.mkdir(local_dir)\n",
    "except FileExistsError:\n",
    "    # directory exists\n",
    "    print(\"Using existing '\" + local_dir + \"' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fixed values\n",
    "params_dict = {\n",
    "    'ww_x_GPS': -1,\n",
    "    'ww_i_reportModel': 133685247,\n",
    "    'ww_i_reportModelXsl': 133685270,\n",
    "    'ww_x_UNITE_ACAD': acad_unit['Informatique']\n",
    "}\n",
    "\n",
    "# Iterate over all the varying params and keep only data for bachelors\n",
    "for year_key, year_value in acad_period.items():\n",
    "    for level_key, level_value in level.items():\n",
    "        for semester_key, semester_value in semester.items():\n",
    "            if 'bachelor' in level_key.lower():\n",
    "                params_dict['ww_x_PERIODE_ACAD'] = year_value\n",
    "                params_dict['ww_x_PERIODE_PEDAGO'] = level_value\n",
    "                params_dict['ww_x_HIVERETE'] = semester_value\n",
    "                \n",
    "                df = get_data(base_url, params_dict)\n",
    "                if not df.empty:\n",
    "                    # Persist dataframe locally with pickle\n",
    "                    filename = year_key + '-' + level_key.replace(' ', '-').lower() + '-' + semester_key\n",
    "                    df.to_pickle(local_dir + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the previous cell should download 60 files!, as you can check with this command:\n",
    "print(len([name for name in os.listdir(local_dir)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hereby show an example of dataframe laoded from the files previously download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_example = pd.read_pickle(local_dir + '/2007-2008-bachelor-semestre-6-printemps')\n",
    "df_example.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
